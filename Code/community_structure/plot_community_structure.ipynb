{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Produce plots for community structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib notebook\n",
    "\n",
    "import os\n",
    "import utils\n",
    "import sys\n",
    "import numpy as np\n",
    "from brainiak.utils import fmrisim as sim\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "from scipy.optimize import curve_fit\n",
    "import colorsys"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate diagrams of community structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "\n",
    "# Make the base graph\n",
    "graph = utils.community_structure(comm_spread=1,\n",
    "                                 )\n",
    "\n",
    "# Make and plot of the mid and low density\n",
    "mid_density = utils.community_structure(comm_spread=0.5,\n",
    "                                )\n",
    "low_density = utils.community_structure(comm_spread=0,\n",
    "                                )\n",
    "\n",
    "# Make all the values positive and scale them to 1\n",
    "mid_density = mid_density + abs(np.min(mid_density))\n",
    "low_density = low_density + abs(np.min(low_density))\n",
    "graph = graph + abs(np.min(graph))\n",
    "\n",
    "mid_density = mid_density / np.max(mid_density)\n",
    "low_density = low_density / np.max(low_density)\n",
    "graph = graph / np.max(graph)\n",
    "\n",
    "# Make random walk path\n",
    "walk = np.asarray([0,2,4,1,3,0,3,4,5,7,9,6,8,5,8,9,10,12,14,11,13,10,13,14])  # A walk for all transitions\n",
    "random_walk = graph[walk, :]\n",
    "plt.plot(random_walk[:, 0], random_walk[:, 1], c=(0.9, 0.9, 0.9))\n",
    "\n",
    "# Plot the nodes\n",
    "plt.scatter(graph[:, 0], graph[:, 1], s=100, c='k', zorder=3)\n",
    "\n",
    "hamilition = np.vstack([graph, graph[0,:]])\n",
    "plt.plot(hamilition[:, 0], hamilition[:, 1], c=(0.9, 0.9, 0.9))\n",
    "\n",
    "# Fix the values\n",
    "plt.title('Community structure graph')\n",
    "plt.axis('off')\n",
    "plt.xlim([-0.1, 1.1])\n",
    "plt.ylim([-0.1, 1.1])\n",
    "plt.savefig('../../community_structure/plots/community_structure_graph.eps', format='eps', dpi=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Make Hamilitonian path\n",
    "plt.figure(figsize=(9,3))\n",
    "high_d = np.vstack([graph, graph[0,:]])\n",
    "plt.subplot(1, 3, 1)\n",
    "plt.plot(high_d[:, 0], high_d[:, 1])\n",
    "plt.axis('off')\n",
    "\n",
    "mid_d = np.vstack([mid_density, mid_density[0,:]])\n",
    "plt.subplot(1, 3, 2)\n",
    "plt.plot(mid_d[:, 0], mid_d[:, 1])\n",
    "plt.axis('off')\n",
    "\n",
    "low_d = np.vstack([low_density, low_density[0,:]])\n",
    "plt.subplot(1, 3, 3)\n",
    "plt.plot(low_d[:, 0], low_d[:, 1])\n",
    "plt.axis('off')\n",
    "\n",
    "plt.savefig('../../community_structure/plots/community_structure_density.eps', format='eps', dpi=1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Figure 1.* Graph depicting the community structure from Schapiro and colleagues (2013). The black circles represent each stimulus (fractals) participants were presented with. The blue and grey lines represent all of the possible transitions when taking a random walk, while the blue alone represents the hamilitonian path that participants took during the test trials. The graph here depicts when the density is 0 and the graph if the density is zero "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compare different signal parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Take the output of the signal_fit function and plot the heatmap of results\n",
    "\n",
    "# Identify file paths\n",
    "signal_fit_path='../../community_structure/signal_fit/'\n",
    "\n",
    "# What is the file name\n",
    "signal_fit_name = signal_fit_path + 'signal_fit.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Load the noise parameters in\n",
    "with open(signal_fit_name, 'r') as f:\n",
    "    text = f.readlines()  # Pull out file as a an array\n",
    "\n",
    "# Pull out the conditions and difference scores\n",
    "sig_data = np.zeros([len(text), 3])\n",
    "counter = 0\n",
    "for line in text:\n",
    "    condition, difference = line.strip().split()\n",
    "    \n",
    "    # Identify the condition variables\n",
    "    density_idx = condition.find('density')\n",
    "    signal_idx = condition.find('_s-')\n",
    "    if density_idx > -1:\n",
    "        density = float(condition[density_idx + 8:signal_idx])\n",
    "    else:\n",
    "        density = 1.0\n",
    "    signal = float(condition[signal_idx + 3:-1])\n",
    "    \n",
    "    # Store the sig_data with the conditions\n",
    "    sig_data[counter, :] = np.asarray([density, signal, float(difference)])\n",
    "    \n",
    "    # Increment counter\n",
    "    counter += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Make a heat map of the results\n",
    "densities = np.sort(np.unique(sig_data[:, 0]))\n",
    "magnitudes = np.sort(np.unique(sig_data[:, 1]))\n",
    "im_sig_data = np.ones([len(densities), len(magnitudes)]) * np.nan\n",
    "\n",
    "# Cycle through density and magnitude\n",
    "used_idx = []\n",
    "for density_counter, density in enumerate(densities):\n",
    "    for magnitude_counter, magnitude in enumerate(magnitudes):\n",
    "        \n",
    "        # Which index has this value\n",
    "        den_idx = sig_data[:, 0] == density\n",
    "        mag_idx = sig_data[:, 1] == magnitude\n",
    "        \n",
    "        # Which index is common between columns and rows\n",
    "        idx = den_idx * mag_idx\n",
    "        \n",
    "        if np.any(idx):\n",
    "            im_sig_data[density_counter, magnitude_counter] = sig_data[np.nonzero(idx), 2][0][0]\n",
    "            \n",
    "            used_idx.append(np.where(idx)[0][0])\n",
    "\n",
    "# Rotate so that it is appropriately oriented\n",
    "im_sig_data = np.flipud(np.rot90(im_sig_data));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Interpolate image sig_data so that nan's are ignored\n",
    "X,Y=np.where(np.isnan(im_sig_data))\n",
    "\n",
    "# Cycle through the nans\n",
    "for nan_counter in list(range(len(X))):\n",
    "    \n",
    "    # Find the idxs surrounding\n",
    "    X_min = X[nan_counter] - 1\n",
    "    X_max = X[nan_counter] + 2\n",
    "    Y_min = Y[nan_counter] - 1\n",
    "    Y_max = Y[nan_counter] + 2\n",
    "    \n",
    "    # Bound\n",
    "    if X_min < 0:\n",
    "        X_min = 0\n",
    "    if Y_min < 0:\n",
    "        Y_min = 0\n",
    "    if X_max > im_sig_data.shape[0]:\n",
    "        X_max = im_sig_data.shape[0]\n",
    "    if Y_max > im_sig_data.shape[1]:\n",
    "        Y_max = im_sig_data.shape[1]\n",
    "        \n",
    "    # Make a mesh\n",
    "    X_mesh, Y_mesh =np.meshgrid(np.arange(X_min, X_max), np.arange(Y_min, Y_max))\n",
    "    \n",
    "    # Insert the interpolated value\n",
    "    im_sig_data[X[nan_counter], Y[nan_counter]] = np.nanmean(im_sig_data[X_mesh, Y_mesh])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Plot a 2d heat map of the difference from the result (be aware the signal is not evenly spaced)\n",
    "plt.figure()\n",
    "plt.imshow(np.flipud(abs(im_sig_data)))\n",
    "\n",
    "# Set values\n",
    "plt.title('Difference between real and simulated data')\n",
    "plt.ylabel('Signal Magnitude')\n",
    "plt.yticks(np.arange(0, len(magnitudes), 2), np.flipud(magnitudes)[::2])\n",
    "#plt.tick_params(which='both', left='off', labelleft='off', bottom='off', labelbottom='off')\n",
    "plt.xlabel('Density')\n",
    "plt.xticks(np.arange(0, len(densities), 2), densities[::2])\n",
    "plt.colorbar()\n",
    "plt.clim((0,5))\n",
    "plt.savefig('../../community_structure/plots/comparison_magnitude_density.eps', format='eps', dpi=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Figure 2.* Heat map of the difference between the real and simulated data with different signal parameters. The Y axis is the signal magnitude (related to the percent signal change) and the X axis is the density of the community structure, where a density of zero is the blue outline in Figure 1 and a density of one is the orange triangle."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Plot the sig_data in 3d\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(111, projection='3d')\n",
    "ax.scatter(sig_data[used_idx, 0], sig_data[used_idx, 1], abs(sig_data[used_idx, 2]))\n",
    "\n",
    "X, Y=np.meshgrid(densities, magnitudes)\n",
    "# fig = plt.figure()\n",
    "# ax = fig.add_subplot(111, projection='3d')\n",
    "ax.plot_surface(X, Y, abs(im_sig_data))\n",
    "\n",
    "# Set values\n",
    "plt.title('Difference between real and simulated data')\n",
    "ax.set_xlabel('Density')\n",
    "ax.set_ylabel('Signal Magnitude')\n",
    "ax.set_zlabel('Difference')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Figure 3.* Similar to Figure 2 this depicts the difference between the real and simulated data with different signal parameters. The Y axis is the signal magnitude (related to the percent signal change) and the X axis is the density of the community structure, where a density of zero is the blue outline in Figure 1 and a density of one is the orange triangle."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Report the signal that is the minimum for each density\n",
    "matched_signal = magnitudes[np.argmin(abs(im_sig_data),0)]\n",
    "print('The signal magnitude that minimizes the difference between the real data and simulated data with different densities:')\n",
    "print('Density:        ' + str(densities))\n",
    "print('Matched Signal: ' + str(matched_signal))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Plot the line representing the transition in density\n",
    "\n",
    "fig = plt.figure()\n",
    "plt.scatter(densities, matched_signal)\n",
    "\n",
    "# model = np.polyfit(x=np.log(density), y=Matched_Signal, deg=1)\n",
    "# prediction = np.poly1d(model)\n",
    "# trendline = prediction(density)\n",
    "\n",
    "# Specify the function for an exponential\n",
    "def exp_func(x, slope1, slope2, intercept):\n",
    "    return slope1 * np.exp(-slope2 * x) + intercept\n",
    "\n",
    "coefs, _ = curve_fit(exp_func, densities, matched_signal)\n",
    "trendline = exp_func(densities, coefs[0], coefs[1], coefs[2])\n",
    "\n",
    "plt.plot(densities, trendline)\n",
    "\n",
    "density_levels = np.asarray([0.0, 0.5, 1.0])\n",
    "signal_levels = np.round(exp_func(density_levels, coefs[0], coefs[1], coefs[2]) * 100) / 100  # Round to 2 DP\n",
    "\n",
    "plt.title('Relationship between density and matched signal')\n",
    "plt.ylabel('Matched Signal Magnitude')\n",
    "plt.xlabel('Density')\n",
    "\n",
    "print('What signal magnitude matches the real data at different amounts of density')\n",
    "print('Density levels: ' + str(density_levels))\n",
    "print('Matched Signal: ' + str(signal_levels))\n",
    "plt.savefig('../../community_structure/plots/minimal_matched_signal_by_density.eps', format='eps', dpi=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Figure 4.* What are the values of density and signal magnitude that minimize the difference between the real and simulated data. The Y axis is the signal magnitude that minimizes the difference between the real and simulated data for a given density and the X axis is the density of the community structure."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Show the effects of different delays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Create a function to take in a list of onsets and output a plot with the onsets and hrfs overlaid on each other\n",
    "def plot_onsets(onsets,\n",
    "               ):\n",
    "    tr_duration=2\n",
    "    temporal_resolution=1\n",
    "    starting_idx = 50 * temporal_resolution\n",
    "    ending_idx = 200 * temporal_resolution\n",
    "    min_hue = 50 / 360\n",
    "    max_hue = 220 /360\n",
    "    hue_steps = np.linspace(min_hue, max_hue, 15)\n",
    "    \n",
    "    # Get coordinate values to use\n",
    "    graph = utils.community_structure(comm_spread=1,\n",
    "                                 )\n",
    "    graph = graph + abs(graph.min())\n",
    "    for node_counter in list(range(0, 15)):\n",
    "        # Create the time course for the signal to be generated\n",
    "        stimfunc = sim.generate_stimfunction(onsets=onsets[node_counter],\n",
    "                                             event_durations=[1],\n",
    "                                             total_time=1000,\n",
    "                                             temporal_resolution=temporal_resolution,\n",
    "                                             )\n",
    "\n",
    "        # Only take the first block of trials \n",
    "        stimfunc = stimfunc[starting_idx:ending_idx]\n",
    "        \n",
    "        # Multiply the coordinate value\n",
    "        stimfunc *= graph[node_counter, 0]\n",
    "        \n",
    "        # Add the stim funcs together\n",
    "        if node_counter == 0:\n",
    "            stimfunc_all = stimfunc\n",
    "        else:\n",
    "            stimfunc_all += stimfunc\n",
    "        \n",
    "        # Interpolate colors allowing a hue\n",
    "\n",
    "        rgb = colorsys.hsv_to_rgb(hue_steps[node_counter], 0.75, 1)\n",
    "        \n",
    "        # Plot each individual event\n",
    "        plt.plot(stimfunc, c=rgb)\n",
    "\n",
    "    # Convolve all of the events with the hrf\n",
    "    hrf = sim.convolve_hrf(stimfunction=stimfunc_all, \n",
    "                           tr_duration=tr_duration, \n",
    "                           temporal_resolution=temporal_resolution,\n",
    "                          )\n",
    "    \n",
    "    # Upsample the hrf to be in seconds (rather than trs)\n",
    "    hrf_interpolated = np.zeros((stimfunc.shape[0],))\n",
    "    for tr_counter in list(range(len(hrf) - 1)):\n",
    "        hrf_interpolated[tr_counter * 2] = hrf[tr_counter]\n",
    "        hrf_interpolated[(tr_counter * 2) + 1] = np.mean([hrf[tr_counter], hrf[tr_counter + 1]])\n",
    "    hrf_interpolated[-1] = hrf[-1]\n",
    "    \n",
    "    # Plot the interpolated hrf\n",
    "    plt.plot(hrf_interpolated, c='g')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Load an example of Anna's dataset and show the effects of different ISIs and randomization\n",
    "\n",
    "# Note, there should only be 12 events because we ignore the first 4\n",
    "\n",
    "signal_fit_path = '../../community_structure/simulator_parameters/timing/sub-1.npy'\n",
    "\n",
    "# Plot the default values\n",
    "onsets = np.load(signal_fit_path)[0]\n",
    "plt.figure()\n",
    "\n",
    "plt.subplot(2, 2, 1)\n",
    "plot_onsets(onsets)\n",
    "plt.title('Minimum ISI:1s')\n",
    "plt.ylabel('Hamilitonian\\nEstimated Response')\n",
    "plt.ylim([0, 5])\n",
    "\n",
    "plt.subplot(2, 2, 2)\n",
    "onsets = np.load(signal_fit_path)[0]\n",
    "plot_onsets(utils.extra_isi(onsets, 5))\n",
    "plt.title('Minimum ISI: 6s')\n",
    "plt.ylim([0, 5])\n",
    "\n",
    "plt.subplot(2, 2, 3)\n",
    "onsets = np.load(signal_fit_path)[0]\n",
    "plot_onsets(utils.randomise_timing(onsets))\n",
    "plt.ylabel('Randomized\\nEstimated Response')\n",
    "plt.xlabel('Added ISI (s)')\n",
    "plt.ylim([0, 5])\n",
    "\n",
    "plt.subplot(2, 2, 4)\n",
    "onsets = np.load(signal_fit_path)[0]\n",
    "plot_onsets(utils.randomise_timing(utils.extra_isi(onsets, 5)))\n",
    "plt.xlabel('Added ISI (s)')\n",
    "plt.ylim([0, 5])\n",
    "plt.savefig('../../community_structure/plots/altered_event_order.eps', format='eps', dpi=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Figure 5.* Estimated response for a single voxel under different experimental designs. The dark green line represents the convolution of the color events with a double gamma HRF. The events are colored across a hue spectrum from teal to blue as you traverse the hamilitonian path"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compare different delay values with a toy simulation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Compare different density and ISI values\n",
    "r_min = -0.5\n",
    "r_max = 1\n",
    "plt.figure()\n",
    "plt.subplot(2, 2, 1)\n",
    "node_brain = utils.toy_simulation(community_density=1, \n",
    "                                  added_isi=0, \n",
    "                                  rand=0,\n",
    "                                  )\n",
    "plt.scatter(node_brain[0, :], node_brain[1, :])\n",
    "plt.xlim([r_min, r_max]); plt.ylim([r_min, r_max])\n",
    "plt.xticks([]); plt.yticks([])\n",
    "plt.title('Added ISI = 0, Hamiliton')\n",
    "plt.ylabel('Density = 1')\n",
    "\n",
    "plt.subplot(2, 2, 2)\n",
    "node_brain = utils.toy_simulation(community_density=1, \n",
    "                                  added_isi=5, \n",
    "                                  rand=0,\n",
    "                                  )\n",
    "plt.scatter(node_brain[0, :], node_brain[1, :])\n",
    "plt.xlim([r_min, r_max]); plt.ylim([r_min, r_max])\n",
    "plt.xticks([]); plt.yticks([])\n",
    "plt.title('Added ISI = 5, Random')\n",
    "\n",
    "plt.subplot(2, 2, 3)\n",
    "node_brain = utils.toy_simulation(community_density=0, \n",
    "                                  added_isi=0, \n",
    "                                  rand=0,\n",
    "                                  )\n",
    "plt.scatter(node_brain[0, :], node_brain[1, :])\n",
    "plt.xlim([r_min, r_max]); plt.ylim([r_min, r_max])\n",
    "plt.xticks([]); plt.yticks([])\n",
    "plt.ylabel('Density = 0')\n",
    "\n",
    "plt.subplot(2, 2, 4)\n",
    "node_brain = utils.toy_simulation(community_density=0, \n",
    "                                  added_isi=5, \n",
    "                                  rand=0,\n",
    "                                  )\n",
    "plt.scatter(node_brain[0, :], node_brain[1, :])\n",
    "plt.xlim([r_min, r_max]); plt.ylim([r_min, r_max])\n",
    "plt.xticks([]); plt.yticks([])\n",
    "plt.savefig('../../community_structure/plots/density_by_event_timing_representation.eps', format='eps', dpi=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Make toy data in order to estimate the trends this way.\n",
    "\n",
    "limit = 0\n",
    "max_delay = 10\n",
    "toy_data = np.zeros((max_delay, 3, 2))\n",
    "toy_signal_levels = np.asarray([3, 1.45, 0.9])\n",
    "density_levels = [0.0, 0.5, 1.0]\n",
    "for density_counter, density in enumerate(density_levels):\n",
    "    signal = toy_signal_levels[density_counter]\n",
    "    for added_isi in list(range(0, max_delay)):\n",
    "        for rand in list(range(2)):\n",
    "            vol = utils.toy_simulation(community_density=density, \n",
    "                                              added_isi=added_isi, \n",
    "                                              rand=rand,\n",
    "                                              signal_magnitude=signal,\n",
    "                                              restrict_overall_duration=limit,\n",
    "                                              )\n",
    "            # Run the analysis\n",
    "            toy_data[added_isi, density_counter, rand] = utils.test_rsa(np.transpose(vol),\n",
    "                                                                         distance_type='distance',\n",
    "                                                                         )\n",
    "            \n",
    "plt.figure()\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(toy_data[:, :, 0])\n",
    "plt.ylim((0, 1))\n",
    "plt.ylabel('Within vs Between distance')\n",
    "plt.xlabel('Added ISI (s)')\n",
    "plt.title('Hamiltonian')\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(toy_data[:, :, 1])\n",
    "plt.ylim((0, 1))\n",
    "plt.legend(density_levels, title='Density')\n",
    "plt.xlabel('Added ISI (s)')\n",
    "plt.title('Randomise')\n",
    "plt.savefig('../../community_structure/plots/toy_delay.eps', format='eps', dpi=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "limit = 1\n",
    "max_delay = 10\n",
    "toy_data = np.zeros((max_delay, 3, 2))\n",
    "toy_signal_levels = np.asarray([3, 1.45, 0.9])\n",
    "density_levels = [0.0, 0.5, 1.0]\n",
    "for density_counter, density in enumerate(density_levels):\n",
    "    signal = toy_signal_levels[density_counter]\n",
    "    for added_isi in list(range(0, max_delay)):\n",
    "        for rand in list(range(1)):\n",
    "            vol = utils.toy_simulation(community_density=density, \n",
    "                                              added_isi=added_isi, \n",
    "                                              rand=rand,\n",
    "                                              signal_magnitude=signal,\n",
    "                                              restrict_overall_duration=limit,\n",
    "                                              )\n",
    "            # Run the analysis\n",
    "            toy_data[added_isi, density_counter, rand] = utils.test_rsa(np.transpose(vol),\n",
    "                                                                        distance_type='distance',\n",
    "                                                                       )\n",
    "\n",
    "plt.figure()\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(toy_data[:, :, 0])\n",
    "plt.ylim((0, 1))\n",
    "plt.ylabel('Within vs Between distance')\n",
    "plt.xlabel('Added ISI (s)')\n",
    "plt.title('Limited Hamiltonian')\n",
    "\n",
    "plt.savefig('../../community_structure/plots/toy_delay_limited.eps', format='eps', dpi=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compare different delay values with a realistic simulation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Find the file names\n",
    "delay_file = '../../community_structure/delay/delay.txt'\n",
    "delay_max = 11  # What is the max delay idx you want to show\n",
    "\n",
    "# Load the noise parameters in\n",
    "with open(delay_file, 'r') as f:\n",
    "    text = f.readlines()  # Pull out file as a an array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Pull out the conditions and difference scores\n",
    "delay_data = {}\n",
    "counter = 0\n",
    "for line in text:\n",
    "    condition, difference = line.strip().split()\n",
    "    \n",
    "    # Identify the condition variables\n",
    "    delay_idx = condition.find('_t-')\n",
    "    randomise_idx = condition.find('_r-')\n",
    "    density_idx = condition.find('density')\n",
    "    signal_idx = condition.find('_s-')\n",
    "    limit_idx = condition.find('limit') \n",
    "    resample_idx = condition.find('_resample-') \n",
    "    \n",
    "\n",
    "    # Identify the condition variables\n",
    "    delay = int(condition[delay_idx + 3:randomise_idx])\n",
    "    randomise = int(condition[randomise_idx + 3:randomise_idx + 4])\n",
    "    if density_idx > -1:\n",
    "        density = float(condition[density_idx + 8:signal_idx])\n",
    "    else:\n",
    "        density = 1.0\n",
    "    signal = condition[signal_idx+ 3:signal_idx + 7]\n",
    "    if signal[-1] == '_':\n",
    "        signal = signal[:-1]\n",
    "    \n",
    "    if limit_idx > -1:\n",
    "        limit = 1\n",
    "    else:\n",
    "        limit = 0\n",
    "    resample = int(condition[resample_idx + 10:-1])\n",
    "    \n",
    "    # Store the sig_data with the conditions\n",
    "    summary_condition = 'r-%d_d-%0.1f_s-%s_l-%d' % (randomise, density, signal, limit)\n",
    "    \n",
    "    # Preset the array if it doesn't exist\n",
    "    if summary_condition not in delay_data:\n",
    "        delay_data[summary_condition] = np.ones((16, 10)) * np.nan\n",
    "    \n",
    "    # Store the data\n",
    "    delay_data[summary_condition][delay, resample - 1] = float(difference)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Summarize the data you have\n",
    "print('Check how many resamples per condition there are')\n",
    "for key in delay_data:\n",
    "    print(key)\n",
    "    print(np.sum(~np.isnan(delay_data[key])[:delay_max], 1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "low_density_sig = '0.5'\n",
    "mid_density_sig = '0.35'\n",
    "high_density_sig = '0.25'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Plot the data along with error\n",
    "\n",
    "def plot_delay_data(delay_data, keys, delay_max):\n",
    "    plt.ylim([-2, 5])\n",
    "    plt.hlines(0, 0, delay_max, linestyles='dashed')\n",
    "    \n",
    "    # Iterate through all the listed keys\n",
    "    for key in keys:\n",
    "        y = delay_data[key][:delay_max, :]\n",
    "        #err = (np.nanstd(y, 1) / np.sqrt(np.sum(~np.isnan(y), 1)))  # Standard error\n",
    "        err = np.nanstd(y, 1)  # Standard deviation\n",
    "        plt.plot(np.arange(delay_max), np.nanmean(y, 1))\n",
    "        plt.fill_between(np.arange(delay_max), np.nanmean(y, 1) + err, np.nanmean(y, 1) - err, alpha=0.5)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Plot the delay at different density levels\n",
    "plt.figure()\n",
    "\n",
    "# Plot the hamilitonian data\n",
    "plt.subplot(1,3,1)\n",
    "\n",
    "keys = ['r-0_d-0.0_s-%s_l-0' % low_density_sig, 'r-0_d-0.5_s-%s_l-0' % mid_density_sig, 'r-0_d-1.0_s-%s_l-0' % high_density_sig]\n",
    "plot_delay_data(delay_data, keys, delay_max)\n",
    "plt.title('A')\n",
    "plt.ylabel('Diff. t stat in ROI')\n",
    "plt.title('Hamiltonian')\n",
    "\n",
    "# Plot the randomised data\n",
    "plt.subplot(1,3,2)\n",
    "keys = ['r-1_d-0.0_s-%s_l-0' % low_density_sig, 'r-1_d-0.5_s-%s_l-0' % mid_density_sig, 'r-1_d-1.0_s-%s_l-0' % high_density_sig]\n",
    "plot_delay_data(delay_data, keys, delay_max)\n",
    "plt.title('B')\n",
    "plt.xlabel('Added ISI (s)')\n",
    "plt.title('Random')\n",
    "\n",
    "# Plot the hamilitonian data with the time limit\n",
    "plt.subplot(1,3,3)\n",
    "keys = ['r-0_d-0.0_s-%s_l-1' % low_density_sig, 'r-0_d-0.5_s-%s_l-1' % mid_density_sig, 'r-0_d-1.0_s-%s_l-1' % high_density_sig]\n",
    "plot_delay_data(delay_data, keys, delay_max)\n",
    "plt.title('C')\n",
    "plt.legend(['0.0', '0.5', '1.0', 'real result'], title='Density')\n",
    "plt.title('Hamiltonian')\n",
    "\n",
    "plt.savefig('../../community_structure/plots/simulated_delay.eps', format='eps', dpi=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Figure 6.* Average t statistic in ROI for different amounts of ISI from 10 simulations of the data. A) Events are presented in a hamiltonian path. B) Events are presented in a random order. C) Number of events are limited by the expeiment duration. Different lines represent different densities of the simulated community structure. The black line represents the real t statistic, shaded lines are standard deviation across resamples."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
